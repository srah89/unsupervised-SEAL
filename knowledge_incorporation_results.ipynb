{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "# SEAL Knowledge Incorporation Results Viewer\n",
        "\n",
        "This notebook provides comprehensive analysis and visualization of SEAL knowledge incorporation experiment results.\n",
        "\n",
        "## Features:\n",
        "- üìä **Summary View**: Quick overview of all experiments\n",
        "- üîç **Detailed Analysis**: Deep dive into specific results\n",
        "- üìà **Comparisons**: Side-by-side experiment comparison\n",
        "- üìã **Interactive Tables**: Browse results with filtering\n",
        "- üé® **Visualizations**: Charts and heatmaps for better understanding\n",
        "\n",
        "## Usage:\n",
        "1. Run the setup cells below\n",
        "2. Use the provided functions to analyze your results\n",
        "3. Customize visualizations as needed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup and imports\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Any, Optional\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "plt.rcParams['font.size'] = 11\n",
        "\n",
        "print(\"‚úÖ Setup complete! Ready to analyze SEAL knowledge incorporation results.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration - Update these paths as needed\n",
        "RESULTS_DIR = Path(\"knowledge-incorporation/results\")\n",
        "\n",
        "# Check if results directory exists\n",
        "if RESULTS_DIR.exists():\n",
        "    print(f\"‚úÖ Found results directory: {RESULTS_DIR}\")\n",
        "    print(f\"üìÅ Available subdirectories:\")\n",
        "    for subdir in RESULTS_DIR.iterdir():\n",
        "        if subdir.is_dir():\n",
        "            file_count = len(list(subdir.glob(\"**/*.json\")))\n",
        "            print(f\"   üìä {subdir.name}: {file_count} JSON files\")\n",
        "else:\n",
        "    print(f\"‚ùå Results directory not found: {RESULTS_DIR}\")\n",
        "    print(\"üí° Please update RESULTS_DIR variable above to point to your results folder\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Helper functions for loading and analyzing results\n",
        "\n",
        "def load_json_file(filepath):\n",
        "    \"\"\"Load JSON file with error handling\"\"\"\n",
        "    try:\n",
        "        with open(filepath, 'r') as f:\n",
        "            return json.load(f)\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading {filepath}: {e}\")\n",
        "        return None\n",
        "\n",
        "def detect_result_type(filepath):\n",
        "    \"\"\"Detect the type of result file\"\"\"\n",
        "    filepath_str = str(filepath)\n",
        "    if \"continual_self_edits\" in filepath_str and \"summary\" in filepath.name:\n",
        "        return \"continual\"\n",
        "    elif filepath.parent.name in [\"eval\", \"train\"] and \"query_server\" in filepath_str:\n",
        "        return \"query_server\"\n",
        "    elif \"cpt_\" in filepath.name:\n",
        "        return \"cpt\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "def find_all_results():\n",
        "    \"\"\"Find all result files organized by type\"\"\"\n",
        "    results = {\"query_server\": [], \"cpt\": [], \"continual\": []}\n",
        "    \n",
        "    if not RESULTS_DIR.exists():\n",
        "        return results\n",
        "    \n",
        "    # Query server results\n",
        "    qs_dir = RESULTS_DIR / \"query_server\"\n",
        "    if qs_dir.exists():\n",
        "        results[\"query_server\"].extend(qs_dir.glob(\"**/*.json\"))\n",
        "    \n",
        "    # CPT results\n",
        "    cpt_dir = RESULTS_DIR / \"cpt\"\n",
        "    if cpt_dir.exists():\n",
        "        results[\"cpt\"].extend(cpt_dir.glob(\"*.json\"))\n",
        "    \n",
        "    # Continual self-edits results\n",
        "    cont_dir = RESULTS_DIR / \"continual_self_edits\"\n",
        "    if cont_dir.exists():\n",
        "        results[\"continual\"].extend(cont_dir.glob(\"**/summary_*.json\"))\n",
        "    \n",
        "    return results\n",
        "\n",
        "print(\"‚úÖ Helper functions loaded\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìä SUMMARY: Overview of All Results\n",
        "\n",
        "def show_summary():\n",
        "    \"\"\"Display a comprehensive summary of all available results\"\"\"\n",
        "    results = find_all_results()\n",
        "    \n",
        "    print(\"üî¨ SEAL Knowledge Incorporation Results Summary\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    summary_data = []\n",
        "    \n",
        "    for result_type, files in results.items():\n",
        "        print(f\"\\nüìä {result_type.upper().replace('_', ' ')} RESULTS:\")\n",
        "        \n",
        "        if not files:\n",
        "            print(\"   No results found\")\n",
        "            continue\n",
        "            \n",
        "        for filepath in sorted(files):\n",
        "            data = load_json_file(filepath)\n",
        "            if not data:\n",
        "                continue\n",
        "                \n",
        "            # Extract key metrics based on result type\n",
        "            if result_type == \"query_server\":\n",
        "                overall = data.get(\"overall\", {})\n",
        "                exp_name = data.get(\"exp_name\", filepath.stem)\n",
        "                baseline_acc = overall.get(\"baseline_mean_accuracy\", 0)\n",
        "                adapter_acc = overall.get(\"adapter_mean_accuracy\", 0)\n",
        "                gain = overall.get(\"mean_gain\", 0)\n",
        "                n_articles = data.get(\"n_articles\", \"?\")\n",
        "                \n",
        "                print(f\"   üìÑ {exp_name}\")\n",
        "                print(f\"      Baseline: {baseline_acc:.3f} ‚Üí Adapter: {adapter_acc:.3f} (Gain: +{gain:.3f})\")\n",
        "                print(f\"      Articles: {n_articles}\")\n",
        "                \n",
        "                summary_data.append({\n",
        "                    'Type': 'Query Server',\n",
        "                    'Name': exp_name,\n",
        "                    'Baseline': baseline_acc,\n",
        "                    'Adapter': adapter_acc,\n",
        "                    'Gain': gain,\n",
        "                    'Articles': n_articles\n",
        "                })\n",
        "                \n",
        "            elif result_type == \"cpt\":\n",
        "                overall = data.get(\"overall\", {})\n",
        "                baseline_acc = overall.get(\"baseline_accuracy\", 0)\n",
        "                adapter_acc = overall.get(\"adapter_accuracy\", 0)\n",
        "                gain = overall.get(\"gain\", 0)\n",
        "                n_articles = data.get(\"n_articles\", \"?\")\n",
        "                \n",
        "                print(f\"   üìÑ {filepath.stem}\")\n",
        "                print(f\"      Baseline: {baseline_acc:.3f} ‚Üí Adapter: {adapter_acc:.3f} (Gain: +{gain:.3f})\")\n",
        "                print(f\"      Articles: {n_articles}\")\n",
        "                \n",
        "                summary_data.append({\n",
        "                    'Type': 'CPT',\n",
        "                    'Name': filepath.stem,\n",
        "                    'Baseline': baseline_acc,\n",
        "                    'Adapter': adapter_acc,\n",
        "                    'Gain': gain,\n",
        "                    'Articles': n_articles\n",
        "                })\n",
        "                \n",
        "            elif result_type == \"continual\":\n",
        "                n_seq = data.get(\"n_sequences\", 0)\n",
        "                n_data = data.get(\"n_datapoints\", 0)\n",
        "                mean_matrix = data.get(\"mean_over_sequences\", [])\n",
        "                \n",
        "                if mean_matrix:\n",
        "                    final_acc = mean_matrix[-1][-1] if mean_matrix[-1] else 0\n",
        "                    initial_acc = mean_matrix[0][0] if mean_matrix[0] else 0\n",
        "                    improvement = final_acc - initial_acc\n",
        "                    \n",
        "                    print(f\"   üìÑ {filepath.parent.name}\")\n",
        "                    print(f\"      Initial: {initial_acc:.3f} ‚Üí Final: {final_acc:.3f} (Change: {improvement:+.3f})\")\n",
        "                    print(f\"      Sequences: {n_seq}, Datapoints: {n_data}\")\n",
        "                    \n",
        "                    summary_data.append({\n",
        "                        'Type': 'Continual',\n",
        "                        'Name': filepath.parent.name,\n",
        "                        'Baseline': initial_acc,\n",
        "                        'Adapter': final_acc,\n",
        "                        'Gain': improvement,\n",
        "                        'Articles': f\"{n_seq}seq√ó{n_data}pts\"\n",
        "                    })\n",
        "    \n",
        "    # Create summary DataFrame\n",
        "    if summary_data:\n",
        "        print(f\"\\nüìã SUMMARY TABLE:\")\n",
        "        df = pd.DataFrame(summary_data)\n",
        "        print(df.to_string(index=False, float_format='%.3f'))\n",
        "        return df\n",
        "    else:\n",
        "        print(\"\\n‚ùå No results found to summarize\")\n",
        "        return None\n",
        "\n",
        "# Run the summary\n",
        "summary_df = show_summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìà VISUALIZATION: Results Overview\n",
        "\n",
        "def plot_summary_comparison(df):\n",
        "    \"\"\"Create comparison plots from summary data\"\"\"\n",
        "    if df is None or df.empty:\n",
        "        print(\"No data to plot\")\n",
        "        return\n",
        "    \n",
        "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "    fig.suptitle('SEAL Knowledge Incorporation Results Overview', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # 1. Accuracy comparison by experiment\n",
        "    ax1 = axes[0, 0]\n",
        "    x = range(len(df))\n",
        "    width = 0.35\n",
        "    \n",
        "    ax1.bar([i - width/2 for i in x], df['Baseline'], width, label='Baseline', alpha=0.8, color='lightcoral')\n",
        "    ax1.bar([i + width/2 for i in x], df['Adapter'], width, label='Adapter', alpha=0.8, color='lightblue')\n",
        "    \n",
        "    ax1.set_xlabel('Experiment')\n",
        "    ax1.set_ylabel('Accuracy')\n",
        "    ax1.set_title('Baseline vs Adapter Accuracy')\n",
        "    ax1.set_xticks(x)\n",
        "    ax1.set_xticklabels(df['Name'], rotation=45, ha='right')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 2. Gain by experiment\n",
        "    ax2 = axes[0, 1]\n",
        "    colors = ['green' if g > 0 else 'red' for g in df['Gain']]\n",
        "    bars = ax2.bar(df['Name'], df['Gain'], color=colors, alpha=0.8)\n",
        "    ax2.set_xlabel('Experiment')\n",
        "    ax2.set_ylabel('Accuracy Gain')\n",
        "    ax2.set_title('Accuracy Gain by Experiment')\n",
        "    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "    \n",
        "    # Add value labels on bars\n",
        "    for bar, gain in zip(bars, df['Gain']):\n",
        "        height = bar.get_height()\n",
        "        ax2.text(bar.get_x() + bar.get_width()/2., height + (0.005 if height >= 0 else -0.01),\n",
        "                f'{gain:.3f}', ha='center', va='bottom' if height >= 0 else 'top', fontsize=9)\n",
        "    \n",
        "    # 3. Performance by experiment type\n",
        "    ax3 = axes[1, 0]\n",
        "    type_summary = df.groupby('Type').agg({'Gain': ['mean', 'std', 'count']}).round(3)\n",
        "    type_summary.columns = ['Mean_Gain', 'Std_Gain', 'Count']\n",
        "    type_summary = type_summary.reset_index()\n",
        "    \n",
        "    bars = ax3.bar(type_summary['Type'], type_summary['Mean_Gain'], \n",
        "                   yerr=type_summary['Std_Gain'], capsize=5, alpha=0.8)\n",
        "    ax3.set_xlabel('Experiment Type')\n",
        "    ax3.set_ylabel('Mean Accuracy Gain')\n",
        "    ax3.set_title('Average Performance by Experiment Type')\n",
        "    ax3.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Add count labels\n",
        "    for bar, count in zip(bars, type_summary['Count']):\n",
        "        height = bar.get_height()\n",
        "        ax3.text(bar.get_x() + bar.get_width()/2., height + 0.005,\n",
        "                f'n={int(count)}', ha='center', va='bottom', fontsize=9)\n",
        "    \n",
        "    # 4. Baseline vs Adapter scatter\n",
        "    ax4 = axes[1, 1]\n",
        "    scatter = ax4.scatter(df['Baseline'], df['Adapter'], \n",
        "                         c=df['Gain'], cmap='RdYlGn', s=100, alpha=0.8)\n",
        "    \n",
        "    # Add diagonal line (no improvement)\n",
        "    lims = [min(ax4.get_xlim()[0], ax4.get_ylim()[0]), \n",
        "            max(ax4.get_xlim()[1], ax4.get_ylim()[1])]\n",
        "    ax4.plot(lims, lims, 'k--', alpha=0.5, zorder=0)\n",
        "    \n",
        "    ax4.set_xlabel('Baseline Accuracy')\n",
        "    ax4.set_ylabel('Adapter Accuracy')\n",
        "    ax4.set_title('Baseline vs Adapter Performance')\n",
        "    ax4.grid(True, alpha=0.3)\n",
        "    \n",
        "    # Add colorbar\n",
        "    cbar = plt.colorbar(scatter, ax=ax4)\n",
        "    cbar.set_label('Accuracy Gain')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Create visualization if we have data\n",
        "if summary_df is not None and not summary_df.empty:\n",
        "    plot_summary_comparison(summary_df)\n",
        "else:\n",
        "    print(\"üìä No data available for visualization\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîç DETAILED ANALYSIS: Examine Specific Results\n",
        "\n",
        "def analyze_query_server_results(filepath):\n",
        "    \"\"\"Detailed analysis of query server results\"\"\"\n",
        "    data = load_json_file(filepath)\n",
        "    if not data:\n",
        "        return\n",
        "    \n",
        "    print(f\"üîç DETAILED ANALYSIS: {filepath.name}\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    overall = data.get(\"overall\", {})\n",
        "    \n",
        "    print(\"üìà OVERALL METRICS:\")\n",
        "    for key, value in overall.items():\n",
        "        if isinstance(value, float):\n",
        "            print(f\"   {key}: {value:.4f}\")\n",
        "        else:\n",
        "            print(f\"   {key}: {value}\")\n",
        "    \n",
        "    print(f\"\\n‚öôÔ∏è EXPERIMENT CONFIG:\")\n",
        "    print(f\"   Dataset: {data.get('dataset', 'N/A')}\")\n",
        "    print(f\"   Articles: {data.get('n_articles', 'N/A')}\")\n",
        "    print(f\"   Completions: {data.get('k_completions', 'N/A')}\")\n",
        "    \n",
        "    lora_params = data.get(\"lora_params\", {})\n",
        "    if lora_params:\n",
        "        print(f\"\\nüîß LORA PARAMETERS:\")\n",
        "        for key, value in lora_params.items():\n",
        "            print(f\"   {key}: {value}\")\n",
        "    \n",
        "    # Analyze per-article performance\n",
        "    articles = data.get(\"articles\", [])\n",
        "    if articles:\n",
        "        print(f\"\\nüìä PER-ARTICLE ANALYSIS:\")\n",
        "        \n",
        "        article_data = []\n",
        "        for art in articles:\n",
        "            if \"stats\" in art:\n",
        "                article_data.append({\n",
        "                    'Title': art[\"title\"][:30] + \"...\" if len(art[\"title\"]) > 30 else art[\"title\"],\n",
        "                    'Baseline': art[\"stats\"][\"baseline_accuracy\"],\n",
        "                    'Adapter': art[\"stats\"][\"adapter_mean_accuracy\"],\n",
        "                    'Gain': art[\"stats\"][\"mean_gain\"]\n",
        "                })\n",
        "        \n",
        "        if article_data:\n",
        "            df = pd.DataFrame(article_data)\n",
        "            \n",
        "            # Show top and bottom performers\n",
        "            df_sorted = df.sort_values('Gain', ascending=False)\n",
        "            \n",
        "            print(\"\\nüèÜ TOP 5 PERFORMERS:\")\n",
        "            print(df_sorted.head().to_string(index=False, float_format='%.3f'))\n",
        "            \n",
        "            print(\"\\nüìâ BOTTOM 5 PERFORMERS:\")\n",
        "            print(df_sorted.tail().to_string(index=False, float_format='%.3f'))\n",
        "            \n",
        "            # Plot article performance distribution\n",
        "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "            \n",
        "            # Gain distribution\n",
        "            ax1.hist(df['Gain'], bins=20, alpha=0.7, edgecolor='black')\n",
        "            ax1.axvline(df['Gain'].mean(), color='red', linestyle='--', \n",
        "                       label=f'Mean: {df[\"Gain\"].mean():.3f}')\n",
        "            ax1.set_xlabel('Accuracy Gain')\n",
        "            ax1.set_ylabel('Number of Articles')\n",
        "            ax1.set_title('Distribution of Accuracy Gains')\n",
        "            ax1.legend()\n",
        "            ax1.grid(True, alpha=0.3)\n",
        "            \n",
        "            # Baseline vs Adapter scatter\n",
        "            scatter = ax2.scatter(df['Baseline'], df['Adapter'], \n",
        "                                c=df['Gain'], cmap='RdYlGn', alpha=0.7)\n",
        "            \n",
        "            # Add diagonal line\n",
        "            lims = [min(ax2.get_xlim()[0], ax2.get_ylim()[0]), \n",
        "                    max(ax2.get_xlim()[1], ax2.get_ylim()[1])]\n",
        "            ax2.plot(lims, lims, 'k--', alpha=0.5)\n",
        "            \n",
        "            ax2.set_xlabel('Baseline Accuracy')\n",
        "            ax2.set_ylabel('Adapter Accuracy')\n",
        "            ax2.set_title('Baseline vs Adapter Accuracy by Article')\n",
        "            plt.colorbar(scatter, ax=ax2, label='Gain')\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "            \n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "            \n",
        "            return df\n",
        "\n",
        "# Example usage - uncomment and modify path as needed\n",
        "# analyze_query_server_results(RESULTS_DIR / \"query_server/eval/base.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìä CONTINUAL SELF-EDITS ANALYSIS\n",
        "\n",
        "def analyze_continual_results(filepath):\n",
        "    \"\"\"Analyze continual self-edits matrix results\"\"\"\n",
        "    data = load_json_file(filepath)\n",
        "    if not data:\n",
        "        return\n",
        "    \n",
        "    print(f\"üîç CONTINUAL SELF-EDITS ANALYSIS: {filepath.name}\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    print(\"üìà EXPERIMENT CONFIG:\")\n",
        "    print(f\"   Sequences: {data.get('n_sequences', 'N/A')}\")\n",
        "    print(f\"   Datapoints: {data.get('n_datapoints', 'N/A')}\")\n",
        "    print(f\"   Dataset: {data.get('dataset', 'N/A')}\")\n",
        "    print(f\"   Base model: {data.get('base_model', 'N/A')}\")\n",
        "    \n",
        "    mean_matrix = data.get(\"mean_over_sequences\", [])\n",
        "    std_matrix = data.get(\"std_over_sequences\", [])\n",
        "    \n",
        "    if not mean_matrix:\n",
        "        print(\"‚ùå No matrix data found\")\n",
        "        return\n",
        "    \n",
        "    # Convert to numpy arrays for easier manipulation\n",
        "    mean_array = np.array(mean_matrix)\n",
        "    std_array = np.array(std_matrix) if std_matrix else None\n",
        "    \n",
        "    n_steps, n_datapoints = mean_array.shape\n",
        "    \n",
        "    print(f\"\\nüìä ACCURACY MATRIX ({n_steps} steps √ó {n_datapoints} datapoints):\")\n",
        "    \n",
        "    # Print matrix in readable format\n",
        "    print(\"   Step\\\\Data \", end=\"\")\n",
        "    for i in range(n_datapoints):\n",
        "        print(f\"    d{i:>2}\", end=\"\")\n",
        "    print()\n",
        "    print(\"   \" + \"-\" * (10 + 6 * n_datapoints))\n",
        "    \n",
        "    for i in range(n_steps):\n",
        "        step_name = \"Base\" if i == 0 else f\"Step{i-1}\"\n",
        "        print(f\"   {step_name:<8} \", end=\"\")\n",
        "        \n",
        "        for j in range(n_datapoints):\n",
        "            if i == 0 or j < i:  # Only show relevant cells\n",
        "                print(f\"{mean_array[i, j]:>6.3f}\", end=\"\")\n",
        "            else:\n",
        "                print(f\"{'':>6}\", end=\"\")\n",
        "        print()\n",
        "    \n",
        "    # Analysis and visualization\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "    fig.suptitle('Continual Self-Edits Analysis', fontsize=16, fontweight='bold')\n",
        "    \n",
        "    # 1. Heatmap of the accuracy matrix\n",
        "    ax1 = axes[0, 0]\n",
        "    \n",
        "    # Create lower triangular matrix for plotting\n",
        "    plot_matrix = np.full((n_steps, n_datapoints), np.nan)\n",
        "    for i in range(n_steps):\n",
        "        max_j = n_datapoints if i == 0 else i\n",
        "        for j in range(min(n_datapoints, max_j)):\n",
        "            plot_matrix[i, j] = mean_array[i, j]\n",
        "    \n",
        "    im = ax1.imshow(plot_matrix, cmap='viridis', aspect='auto')\n",
        "    ax1.set_title('Accuracy Matrix Heatmap')\n",
        "    ax1.set_xlabel('Datapoint')\n",
        "    ax1.set_ylabel('Training Step')\n",
        "    ax1.set_xticks(range(n_datapoints))\n",
        "    ax1.set_xticklabels([f'd{i}' for i in range(n_datapoints)])\n",
        "    ax1.set_yticks(range(n_steps))\n",
        "    ax1.set_yticklabels(['Base'] + [f'Step{i}' for i in range(n_steps-1)])\n",
        "    plt.colorbar(im, ax=ax1, label='Accuracy')\n",
        "    \n",
        "    # Add text annotations\n",
        "    for i in range(n_steps):\n",
        "        max_j = n_datapoints if i == 0 else i\n",
        "        for j in range(min(n_datapoints, max_j)):\n",
        "            if not np.isnan(plot_matrix[i, j]):\n",
        "                ax1.text(j, i, f'{plot_matrix[i, j]:.2f}', \n",
        "                        ha='center', va='center', fontsize=8)\n",
        "    \n",
        "    # 2. Diagonal progression (how each datapoint evolves)\n",
        "    ax2 = axes[0, 1]\n",
        "    for j in range(min(n_datapoints, n_steps-1)):\n",
        "        values = [mean_array[0, j]] + [mean_array[i+1, j] for i in range(j+1)]\n",
        "        steps = ['Base'] + [f'Step{i}' for i in range(j+1)]\n",
        "        ax2.plot(steps, values, 'o-', label=f'Datapoint {j}', alpha=0.8)\n",
        "    \n",
        "    ax2.set_title('Performance Evolution by Datapoint')\n",
        "    ax2.set_xlabel('Training Step')\n",
        "    ax2.set_ylabel('Accuracy')\n",
        "    ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)\n",
        "    \n",
        "    # 3. Final step performance comparison\n",
        "    ax3 = axes[1, 0]\n",
        "    if n_steps > 1:\n",
        "        final_step_data = []\n",
        "        for j in range(min(n_datapoints, n_steps-1)):\n",
        "            final_step_data.append({\n",
        "                'Datapoint': f'd{j}',\n",
        "                'Base': mean_array[0, j],\n",
        "                'Final': mean_array[j+1, j],\n",
        "                'Change': mean_array[j+1, j] - mean_array[0, j]\n",
        "            })\n",
        "        \n",
        "        if final_step_data:\n",
        "            df_final = pd.DataFrame(final_step_data)\n",
        "            \n",
        "            x = range(len(df_final))\n",
        "            width = 0.35\n",
        "            \n",
        "            bars1 = ax3.bar([i - width/2 for i in x], df_final['Base'], width, \n",
        "                           label='Base', alpha=0.8)\n",
        "            bars2 = ax3.bar([i + width/2 for i in x], df_final['Final'], width, \n",
        "                           label='Final', alpha=0.8)\n",
        "            \n",
        "            ax3.set_title('Base vs Final Performance')\n",
        "            ax3.set_xlabel('Datapoint')\n",
        "            ax3.set_ylabel('Accuracy')\n",
        "            ax3.set_xticks(x)\n",
        "            ax3.set_xticklabels(df_final['Datapoint'])\n",
        "            ax3.legend()\n",
        "            ax3.grid(True, alpha=0.3)\n",
        "    \n",
        "    # 4. Performance statistics\n",
        "    ax4 = axes[1, 1]\n",
        "    \n",
        "    # Calculate statistics for each step\n",
        "    step_stats = []\n",
        "    for i in range(n_steps):\n",
        "        if i == 0:\n",
        "            valid_values = mean_array[i, :n_datapoints]\n",
        "        else:\n",
        "            valid_values = mean_array[i, :i]\n",
        "        \n",
        "        if len(valid_values) > 0:\n",
        "            step_stats.append({\n",
        "                'Step': 'Base' if i == 0 else f'Step{i-1}',\n",
        "                'Mean': np.mean(valid_values),\n",
        "                'Std': np.std(valid_values),\n",
        "                'Min': np.min(valid_values),\n",
        "                'Max': np.max(valid_values),\n",
        "                'Count': len(valid_values)\n",
        "            })\n",
        "    \n",
        "    if step_stats:\n",
        "        df_stats = pd.DataFrame(step_stats)\n",
        "        \n",
        "        ax4.errorbar(range(len(df_stats)), df_stats['Mean'], \n",
        "                    yerr=df_stats['Std'], fmt='o-', capsize=5)\n",
        "        ax4.fill_between(range(len(df_stats)), \n",
        "                        df_stats['Min'], df_stats['Max'], alpha=0.3)\n",
        "        \n",
        "        ax4.set_title('Performance Statistics by Step')\n",
        "        ax4.set_xlabel('Training Step')\n",
        "        ax4.set_ylabel('Accuracy')\n",
        "        ax4.set_xticks(range(len(df_stats)))\n",
        "        ax4.set_xticklabels(df_stats['Step'], rotation=45)\n",
        "        ax4.grid(True, alpha=0.3)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "    return mean_array, std_array\n",
        "\n",
        "# Example usage - uncomment and modify path as needed\n",
        "# analyze_continual_results(RESULTS_DIR / \"continual_self_edits/run0/summary_1748902664.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîÑ EXPERIMENT COMPARISON\n",
        "\n",
        "def compare_experiments(experiment_names):\n",
        "    \"\"\"Compare multiple experiments side by side\"\"\"\n",
        "    print(\"üîÑ EXPERIMENT COMPARISON\")\n",
        "    print(\"=\" * 70)\n",
        "    \n",
        "    results = []\n",
        "    \n",
        "    # Try to find results for each experiment name\n",
        "    for exp_name in experiment_names:\n",
        "        found_files = []\n",
        "        \n",
        "        # Search in query_server/eval\n",
        "        eval_dir = RESULTS_DIR / \"query_server\" / \"eval\"\n",
        "        if eval_dir.exists():\n",
        "            found_files.extend(eval_dir.glob(f\"{exp_name}.json\"))\n",
        "        \n",
        "        # Search in cpt\n",
        "        cpt_dir = RESULTS_DIR / \"cpt\"\n",
        "        if cpt_dir.exists():\n",
        "            found_files.extend(cpt_dir.glob(f\"cpt_{exp_name}.json\"))\n",
        "        \n",
        "        if found_files:\n",
        "            data = load_json_file(found_files[0])\n",
        "            if data:\n",
        "                results.append((exp_name, data, found_files[0]))\n",
        "        else:\n",
        "            print(f\"‚ö†Ô∏è  No results found for experiment: {exp_name}\")\n",
        "    \n",
        "    if len(results) < 2:\n",
        "        print(\"‚ùå Need at least 2 experiments to compare\")\n",
        "        return None\n",
        "    \n",
        "    # Extract comparison data\n",
        "    comparison_data = []\n",
        "    for exp_name, data, filepath in results:\n",
        "        result_type = detect_result_type(filepath)\n",
        "        \n",
        "        if result_type == \"query_server\":\n",
        "            overall = data.get(\"overall\", {})\n",
        "            baseline = overall.get(\"baseline_mean_accuracy\", 0)\n",
        "            adapter = overall.get(\"adapter_mean_accuracy\", 0)\n",
        "            gain = overall.get(\"mean_gain\", 0)\n",
        "        elif result_type == \"cpt\":\n",
        "            overall = data.get(\"overall\", {})\n",
        "            baseline = overall.get(\"baseline_accuracy\", 0)\n",
        "            adapter = overall.get(\"adapter_accuracy\", 0)\n",
        "            gain = overall.get(\"gain\", 0)\n",
        "        else:\n",
        "            continue\n",
        "            \n",
        "        n_articles = data.get(\"n_articles\", \"?\")\n",
        "        \n",
        "        comparison_data.append({\n",
        "            'Experiment': exp_name,\n",
        "            'Type': result_type,\n",
        "            'Baseline': baseline,\n",
        "            'Adapter': adapter,\n",
        "            'Gain': gain,\n",
        "            'Articles': n_articles,\n",
        "            'Dataset': data.get('dataset', 'N/A')\n",
        "        })\n",
        "    \n",
        "    if not comparison_data:\n",
        "        print(\"‚ùå No comparable data found\")\n",
        "        return None\n",
        "    \n",
        "    # Create comparison DataFrame\n",
        "    df = pd.DataFrame(comparison_data)\n",
        "    \n",
        "    print(\"üìä COMPARISON TABLE:\")\n",
        "    print(df.to_string(index=False, float_format='%.4f'))\n",
        "    \n",
        "    # Create comparison visualizations\n",
        "    if len(df) > 1:\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        fig.suptitle('Experiment Comparison', fontsize=16, fontweight='bold')\n",
        "        \n",
        "        # 1. Accuracy comparison\n",
        "        ax1 = axes[0, 0]\n",
        "        x = range(len(df))\n",
        "        width = 0.35\n",
        "        \n",
        "        ax1.bar([i - width/2 for i in x], df['Baseline'], width, \n",
        "               label='Baseline', alpha=0.8, color='lightcoral')\n",
        "        ax1.bar([i + width/2 for i in x], df['Adapter'], width, \n",
        "               label='Adapter', alpha=0.8, color='lightblue')\n",
        "        \n",
        "        ax1.set_xlabel('Experiment')\n",
        "        ax1.set_ylabel('Accuracy')\n",
        "        ax1.set_title('Baseline vs Adapter Accuracy')\n",
        "        ax1.set_xticks(x)\n",
        "        ax1.set_xticklabels(df['Experiment'], rotation=45, ha='right')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        \n",
        "        # 2. Gain comparison\n",
        "        ax2 = axes[0, 1]\n",
        "        colors = ['green' if g > 0 else 'red' for g in df['Gain']]\n",
        "        bars = ax2.bar(df['Experiment'], df['Gain'], color=colors, alpha=0.8)\n",
        "        ax2.set_xlabel('Experiment')\n",
        "        ax2.set_ylabel('Accuracy Gain')\n",
        "        ax2.set_title('Accuracy Gain by Experiment')\n",
        "        ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45, ha='right')\n",
        "        \n",
        "        # Add value labels on bars\n",
        "        for bar, gain in zip(bars, df['Gain']):\n",
        "            height = bar.get_height()\n",
        "            ax2.text(bar.get_x() + bar.get_width()/2., \n",
        "                    height + (0.002 if height >= 0 else -0.005),\n",
        "                    f'{gain:.3f}', ha='center', \n",
        "                    va='bottom' if height >= 0 else 'top', fontsize=10)\n",
        "        \n",
        "        # 3. Baseline vs Adapter scatter\n",
        "        ax3 = axes[1, 0]\n",
        "        scatter = ax3.scatter(df['Baseline'], df['Adapter'], \n",
        "                            c=df['Gain'], cmap='RdYlGn', s=100, alpha=0.8)\n",
        "        \n",
        "        # Add diagonal line (no improvement)\n",
        "        lims = [min(ax3.get_xlim()[0], ax3.get_ylim()[0]), \n",
        "                max(ax3.get_xlim()[1], ax3.get_ylim()[1])]\n",
        "        ax3.plot(lims, lims, 'k--', alpha=0.5, zorder=0)\n",
        "        \n",
        "        ax3.set_xlabel('Baseline Accuracy')\n",
        "        ax3.set_ylabel('Adapter Accuracy')\n",
        "        ax3.set_title('Baseline vs Adapter Performance')\n",
        "        ax3.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Add experiment labels\n",
        "        for i, exp in enumerate(df['Experiment']):\n",
        "            ax3.annotate(exp, (df['Baseline'].iloc[i], df['Adapter'].iloc[i]),\n",
        "                        xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
        "        \n",
        "        # Add colorbar\n",
        "        cbar = plt.colorbar(scatter, ax=ax3)\n",
        "        cbar.set_label('Accuracy Gain')\n",
        "        \n",
        "        # 4. Performance ranking\n",
        "        ax4 = axes[1, 1]\n",
        "        df_sorted = df.sort_values('Gain', ascending=True)\n",
        "        \n",
        "        colors = ['green' if g > 0 else 'red' for g in df_sorted['Gain']]\n",
        "        bars = ax4.barh(range(len(df_sorted)), df_sorted['Gain'], color=colors, alpha=0.8)\n",
        "        \n",
        "        ax4.set_yticks(range(len(df_sorted)))\n",
        "        ax4.set_yticklabels(df_sorted['Experiment'])\n",
        "        ax4.set_xlabel('Accuracy Gain')\n",
        "        ax4.set_title('Performance Ranking')\n",
        "        ax4.axvline(x=0, color='black', linestyle='-', alpha=0.3)\n",
        "        ax4.grid(True, alpha=0.3)\n",
        "        \n",
        "        # Add value labels\n",
        "        for i, (bar, gain) in enumerate(zip(bars, df_sorted['Gain'])):\n",
        "            width = bar.get_width()\n",
        "            ax4.text(width + (0.002 if width >= 0 else -0.005), bar.get_y() + bar.get_height()/2.,\n",
        "                    f'{gain:.3f}', ha='left' if width >= 0 else 'right', va='center', fontsize=10)\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "    \n",
        "    return df\n",
        "\n",
        "# Example usage - uncomment and modify experiment names as needed\n",
        "# compare_experiments(['base', 'iter1', 'iter2'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ QUICK ACCESS: Easy Analysis Functions\n",
        "\n",
        "def quick_analysis():\n",
        "    \"\"\"One-click analysis of all available results\"\"\"\n",
        "    print(\"üéØ QUICK ANALYSIS: Running comprehensive analysis...\")\n",
        "    \n",
        "    results = find_all_results()\n",
        "    \n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "    print(\"üìä SUMMARY\")\n",
        "    print(\"=\"*50)\n",
        "    summary_df = show_summary()\n",
        "    \n",
        "    # Auto-compare available experiments\n",
        "    if summary_df is not None and len(summary_df) > 1:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"üîÑ AUTO-COMPARISON\")\n",
        "        print(\"=\"*50)\n",
        "        unique_names = summary_df['Name'].tolist()\n",
        "        if len(unique_names) > 1:\n",
        "            compare_experiments(unique_names[:5])  # Compare up to 5 experiments\n",
        "    \n",
        "    # Analyze first continual result if available\n",
        "    continual_files = results.get(\"continual\", [])\n",
        "    if continual_files:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"üìä CONTINUAL ANALYSIS\")\n",
        "        print(\"=\"*50)\n",
        "        analyze_continual_results(continual_files[0])\n",
        "    \n",
        "    # Analyze first query server result if available\n",
        "    qs_files = results.get(\"query_server\", [])\n",
        "    if qs_files:\n",
        "        print(\"\\n\" + \"=\"*50)\n",
        "        print(\"üîç DETAILED QUERY SERVER ANALYSIS\")\n",
        "        print(\"=\"*50)\n",
        "        analyze_query_server_results(qs_files[0])\n",
        "\n",
        "def list_available_files():\n",
        "    \"\"\"List all available result files for manual analysis\"\"\"\n",
        "    results = find_all_results()\n",
        "    \n",
        "    print(\"üìÅ AVAILABLE RESULT FILES:\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    for result_type, files in results.items():\n",
        "        if files:\n",
        "            print(f\"\\nüìä {result_type.upper().replace('_', ' ')} FILES:\")\n",
        "            for i, filepath in enumerate(files, 1):\n",
        "                rel_path = filepath.relative_to(RESULTS_DIR)\n",
        "                print(f\"   {i}. {rel_path}\")\n",
        "                \n",
        "                # Show quick stats\n",
        "                data = load_json_file(filepath)\n",
        "                if data and result_type == \"query_server\":\n",
        "                    overall = data.get(\"overall\", {})\n",
        "                    gain = overall.get(\"mean_gain\", 0)\n",
        "                    print(f\"      ‚Üí Gain: {gain:+.3f}\")\n",
        "                elif data and result_type == \"cpt\":\n",
        "                    overall = data.get(\"overall\", {})\n",
        "                    gain = overall.get(\"gain\", 0)\n",
        "                    print(f\"      ‚Üí Gain: {gain:+.3f}\")\n",
        "                elif data and result_type == \"continual\":\n",
        "                    n_seq = data.get(\"n_sequences\", 0)\n",
        "                    n_data = data.get(\"n_datapoints\", 0)\n",
        "                    print(f\"      ‚Üí {n_seq} sequences √ó {n_data} datapoints\")\n",
        "\n",
        "# Run quick analysis\n",
        "print(\"üéØ Ready for analysis! Use the functions below:\")\n",
        "print()\n",
        "print(\"üìã Available functions:\")\n",
        "print(\"‚Ä¢ quick_analysis()                           - Run comprehensive analysis\")\n",
        "print(\"‚Ä¢ list_available_files()                     - List all result files\") \n",
        "print(\"‚Ä¢ show_summary()                             - Show results summary\")\n",
        "print(\"‚Ä¢ compare_experiments(['exp1', 'exp2'])      - Compare specific experiments\")\n",
        "print(\"‚Ä¢ analyze_query_server_results(filepath)     - Detailed query server analysis\")\n",
        "print(\"‚Ä¢ analyze_continual_results(filepath)        - Detailed continual analysis\")\n",
        "print()\n",
        "print(\"üí° Tip: Start with quick_analysis() for a comprehensive overview!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ RUN ANALYSIS\n",
        "# Uncomment the function you want to run:\n",
        "\n",
        "# Quick comprehensive analysis of everything\n",
        "# quick_analysis()\n",
        "\n",
        "# List all available files\n",
        "list_available_files()\n",
        "\n",
        "# Show just the summary\n",
        "# show_summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
